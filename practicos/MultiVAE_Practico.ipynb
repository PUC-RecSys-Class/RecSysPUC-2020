{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "MultiVAE_Practico.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99ahq3V1FYhx"
      },
      "source": [
        "# Variational autoencoders for collaborative filtering "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpghG7ADFYhy"
      },
      "source": [
        "This notebook accompanies the paper \"*Variational autoencoders for collaborative filtering*\" by Dawen Liang, Rahul G. Krishnan, Matthew D. Hoffman, and Tony Jebara, in The Web Conference (aka WWW) 2018.\n",
        "\n",
        "In this notebook, we will show a complete self-contained example of training a variational autoencoder (as well as a denoising autoencoder) with multinomial likelihood (described in the paper) on the public Movielens-20M dataset, including both data preprocessing and model training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOzM2Du1O1ot",
        "outputId": "ae22c073-2a36-40b0-8f1f-00e5922fdce0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "!pip install tensorflow-gpu==1.14"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/6d/2348df00a34baaabdef0fdb4f46f962f7a8a6720362c26c3a44a249767ea/tensorflow_gpu-1.14.0-cp27-cp27mu-manylinux1_x86_64.whl (377.0MB)\n",
            "\u001b[K     |████████████████████████████████| 377.0MB 40kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.15.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (2.0.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.0.8)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/37/e6a7af1c92c5b68fb427f853b06164b56ea92126bcfd87784334ec5e4d42/tensorboard-1.14.0-py2-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 44.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.11.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (3.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (0.2.2)\n",
            "Requirement already satisfied: enum34>=1.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.1.6)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (0.35.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.16.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (0.7.1)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 42.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (0.1.7)\n",
            "Requirement already satisfied: backports.weakref>=1.0rc1 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.0.post1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (0.8.0)\n",
            "Requirement already satisfied: futures>=2.2.0 in /usr/local/lib/python2.7/dist-packages (from grpcio>=1.8.6->tensorflow-gpu==1.14) (3.2.0)\n",
            "Requirement already satisfied: funcsigs>=1; python_version < \"3.3\" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow-gpu==1.14) (1.0.2)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow-gpu==1.14) (5.4.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python2.7/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14) (2.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (44.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (0.15.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (3.1.1)\n",
            "\u001b[31mERROR: tensorflow 2.1.0 has requirement tensorboard<2.2.0,>=2.1.0, but you'll have tensorboard 1.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.1.0 has requirement tensorflow-estimator<2.2.0,>=2.1.0rc0, but you'll have tensorflow-estimator 1.14.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow-gpu\n",
            "  Found existing installation: tensorboard 2.1.0\n",
            "    Uninstalling tensorboard-2.1.0:\n",
            "      Successfully uninstalled tensorboard-2.1.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.0\n",
            "    Uninstalling tensorflow-estimator-1.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.0\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-estimator-1.14.0 tensorflow-gpu-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9EU9SzAI1Vs",
        "outputId": "c962ce95-35fb-4d3d-e574-f46bf36bb663",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!pip install Bottleneck"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Bottleneck\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/08/278c6ee569458e168096f6b51019cc1c81c288da3d1026a22ee2ccead102/Bottleneck-1.3.2.tar.gz (88kB)\n",
            "\r\u001b[K     |███▊                            | 10kB 17.9MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 20kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 30kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 40kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 51kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 61kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 71kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 81kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 4.9MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (from Bottleneck) (1.16.4)\n",
            "Building wheels for collected packages: Bottleneck\n",
            "  Building wheel for Bottleneck (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Bottleneck: filename=Bottleneck-1.3.2-cp27-cp27mu-linux_x86_64.whl size=315109 sha256=9742a8fbb54dec0a270d096704d53fa2a9a4583791fd58fceb389fac2aa8bdfb\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/a9/12/41b13e8b44889ab05ec4dcc91f27da21634bacf2a0e87473b8\n",
            "Successfully built Bottleneck\n",
            "Installing collected packages: Bottleneck\n",
            "Successfully installed Bottleneck-1.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cK_96uetFYhz"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sn\n",
        "sn.set()\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib.layers import apply_regularization, l2_regularizer\n",
        "\n",
        "import bottleneck as bn"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns8jolZYFYh4"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5WFiDZRFYh5"
      },
      "source": [
        "We load the data and create train/validation/test splits following strong generalization: \n",
        "\n",
        "- We split all users into training/validation/test sets. \n",
        "\n",
        "- We train models using the entire click history of the training users. \n",
        "\n",
        "- To evaluate, we take part of the click history from held-out (validation and test) users to learn the necessary user-level representations for the model and then compute metrics by looking at how well the model ranks the rest of the unseen click history from the held-out users."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmGA2EPQFYh6"
      },
      "source": [
        "First, download the dataset at http://files.grouplens.org/datasets/movielens/ml-20m.zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA4ezX8MJUA1",
        "outputId": "0a4f8327-fdfa-4231-a97b-be663ec733be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!wget http://files.grouplens.org/datasets/movielens/ml-20m.zip\n",
        "!unzip /content/ml-20m.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-19 05:22:16--  http://files.grouplens.org/datasets/movielens/ml-20m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 198702078 (189M) [application/zip]\n",
            "Saving to: ‘ml-20m.zip’\n",
            "\n",
            "ml-20m.zip          100%[===================>] 189.50M  27.5MB/s    in 7.6s    \n",
            "\n",
            "2020-10-19 05:22:24 (24.9 MB/s) - ‘ml-20m.zip’ saved [198702078/198702078]\n",
            "\n",
            "Archive:  /content/ml-20m.zip\n",
            "   creating: ml-20m/\n",
            "  inflating: ml-20m/genome-scores.csv  \n",
            "  inflating: ml-20m/genome-tags.csv  \n",
            "  inflating: ml-20m/links.csv        \n",
            "  inflating: ml-20m/movies.csv       \n",
            "  inflating: ml-20m/ratings.csv      \n",
            "  inflating: ml-20m/README.txt       \n",
            "  inflating: ml-20m/tags.csv         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-80sYNYFYh7"
      },
      "source": [
        "### change `DATA_DIR` to the location where movielens-20m dataset sits\n",
        "DATA_DIR = '/content/ml-20m'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnwdl8CbFYiA"
      },
      "source": [
        "raw_data = pd.read_csv(os.path.join(DATA_DIR, 'ratings.csv'), header=0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kn_jtYGHFYiE"
      },
      "source": [
        "# binarize the data (only keep ratings >= 4)\n",
        "raw_data = raw_data[raw_data['rating'] > 3.5]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ehnKTGiFYiJ",
        "outputId": "473004d2-f129-4ddc-f48f-0a8ecaf190c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "raw_data.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    userId  movieId  rating   timestamp\n",
              "6        1      151     4.0  1094785734\n",
              "7        1      223     4.0  1112485573\n",
              "8        1      253     4.0  1112484940\n",
              "9        1      260     4.0  1112484826\n",
              "10       1      293     4.0  1112484703"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>151</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1094785734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>223</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1112485573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>253</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1112484940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>260</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1112484826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>293</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1112484703</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzYgRQIiFYiO"
      },
      "source": [
        "### Data splitting procedure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qVs5EEqFYiP"
      },
      "source": [
        "- Select 10K users as heldout users, 10K users as validation users, and the rest of the users for training\n",
        "- Use all the items from the training users as item set\n",
        "- For each of both validation and test user, subsample 80% as fold-in data and the rest for prediction "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDPvNl-QFYiQ"
      },
      "source": [
        "def get_count(tp, id):\n",
        "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
        "    count = playcount_groupbyid.size()\n",
        "    return count"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKYy5rGjFYiU"
      },
      "source": [
        "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
        "    # Only keep the triplets for items which were clicked on by at least min_sc users. \n",
        "    if min_sc > 0:\n",
        "        itemcount = get_count(tp, 'movieId')\n",
        "        tp = tp[tp['movieId'].isin(itemcount.index[itemcount >= min_sc])]\n",
        "    \n",
        "    # Only keep the triplets for users who clicked on at least min_uc items\n",
        "    # After doing this, some of the items will have less than min_uc users, but should only be a small proportion\n",
        "    if min_uc > 0:\n",
        "        usercount = get_count(tp, 'userId')\n",
        "        tp = tp[tp['userId'].isin(usercount.index[usercount >= min_uc])]\n",
        "    \n",
        "    # Update both usercount and itemcount after filtering\n",
        "    usercount, itemcount = get_count(tp, 'userId'), get_count(tp, 'movieId') \n",
        "    return tp, usercount, itemcount"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWYHa34vFYiX"
      },
      "source": [
        "Only keep items that are clicked on by at least 5 users"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8ytmY4lFYiX"
      },
      "source": [
        "raw_data, user_activity, item_popularity = filter_triplets(raw_data)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay8PGVQDFYia",
        "outputId": "2e922336-ae81-48ab-e0df-2a627abd7776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sparsity = 1. * raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
        "\n",
        "print(\"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
        "      (raw_data.shape[0], user_activity.shape[0], item_popularity.shape[0], sparsity * 100))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After filtering, there are 9990682 watching events from 136677 users and 20720 movies (sparsity: 0.353%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vientq_DFYic"
      },
      "source": [
        "unique_uid = user_activity.index\n",
        "\n",
        "np.random.seed(98765)\n",
        "idx_perm = np.random.permutation(unique_uid.size)\n",
        "unique_uid = unique_uid[idx_perm]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDe3B_KYFYif"
      },
      "source": [
        "# create train/validation/test users\n",
        "n_users = unique_uid.size\n",
        "n_heldout_users = 10000\n",
        "\n",
        "tr_users = unique_uid[:(n_users - n_heldout_users * 2)]\n",
        "vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)]\n",
        "te_users = unique_uid[(n_users - n_heldout_users):]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60FBs88zFYih"
      },
      "source": [
        "train_plays = raw_data.loc[raw_data['userId'].isin(tr_users)]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxCxoAh1FYik"
      },
      "source": [
        "unique_sid = pd.unique(train_plays['movieId'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCcfXDUvFYin"
      },
      "source": [
        "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
        "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKgIGJy1FYiq"
      },
      "source": [
        "pro_dir = os.path.join(DATA_DIR, 'pro_sg')\n",
        "\n",
        "if not os.path.exists(pro_dir):\n",
        "    os.makedirs(pro_dir)\n",
        "\n",
        "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n",
        "    for sid in unique_sid:\n",
        "        f.write('%s\\n' % sid)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fG-zwHSFYis"
      },
      "source": [
        "def split_train_test_proportion(data, test_prop=0.2):\n",
        "    data_grouped_by_user = data.groupby('userId')\n",
        "    tr_list, te_list = list(), list()\n",
        "\n",
        "    np.random.seed(98765)\n",
        "\n",
        "    for i, (_, group) in enumerate(data_grouped_by_user):\n",
        "        n_items_u = len(group)\n",
        "\n",
        "        if n_items_u >= 5:\n",
        "            idx = np.zeros(n_items_u, dtype='bool')\n",
        "            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
        "\n",
        "            tr_list.append(group[np.logical_not(idx)])\n",
        "            te_list.append(group[idx])\n",
        "        else:\n",
        "            tr_list.append(group)\n",
        "\n",
        "        if i % 1000 == 0:\n",
        "            print(\"%d users sampled\" % i)\n",
        "            sys.stdout.flush()\n",
        "\n",
        "    data_tr = pd.concat(tr_list)\n",
        "    data_te = pd.concat(te_list)\n",
        "    \n",
        "    return data_tr, data_te"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1k2d_g2FYiu"
      },
      "source": [
        "vad_plays = raw_data.loc[raw_data['userId'].isin(vd_users)]\n",
        "vad_plays = vad_plays.loc[vad_plays['movieId'].isin(unique_sid)]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJU3Ncf7FYiw",
        "outputId": "6cbaec46-ad18-425f-b2d9-cfa736769789",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 users sampled\n",
            "1000 users sampled\n",
            "2000 users sampled\n",
            "3000 users sampled\n",
            "4000 users sampled\n",
            "5000 users sampled\n",
            "6000 users sampled\n",
            "7000 users sampled\n",
            "8000 users sampled\n",
            "9000 users sampled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptvFIhlsFYiy"
      },
      "source": [
        "test_plays = raw_data.loc[raw_data['userId'].isin(te_users)]\n",
        "test_plays = test_plays.loc[test_plays['movieId'].isin(unique_sid)]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX261EFPFYi1",
        "outputId": "c0f0ed84-4307-4638-de31-41a588b00a7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 users sampled\n",
            "1000 users sampled\n",
            "2000 users sampled\n",
            "3000 users sampled\n",
            "4000 users sampled\n",
            "5000 users sampled\n",
            "6000 users sampled\n",
            "7000 users sampled\n",
            "8000 users sampled\n",
            "9000 users sampled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfPenbm2FYi3"
      },
      "source": [
        "### Save the data into (user_index, item_index) format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfJU_gBkFYi3"
      },
      "source": [
        "def numerize(tp):\n",
        "    uid = map(lambda x: profile2id[x], tp['userId'])\n",
        "    sid = map(lambda x: show2id[x], tp['movieId'])\n",
        "    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUTKUFEAFYi6"
      },
      "source": [
        "train_data = numerize(train_plays)\n",
        "train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ArJf0e8FYi8"
      },
      "source": [
        "vad_data_tr = numerize(vad_plays_tr)\n",
        "vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugbb4-ThFYi_"
      },
      "source": [
        "vad_data_te = numerize(vad_plays_te)\n",
        "vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_17Rkt3jFYjB"
      },
      "source": [
        "test_data_tr = numerize(test_plays_tr)\n",
        "test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iG-vxzWFYjD"
      },
      "source": [
        "test_data_te = numerize(test_plays_te)\n",
        "test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBJhcqMbFYjF"
      },
      "source": [
        "## Model definition and training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlEMlH6TFYjF"
      },
      "source": [
        "We define two related models: denoising autoencoder with multinomial likelihood (Multi-DAE in the paper) and partially-regularized variational autoencoder with multinomial likelihood (Multi-VAE^{PR} in the paper)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZNtUyqeFYjF"
      },
      "source": [
        "### Model definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcrNQ2mYFYjG"
      },
      "source": [
        "__Notations__: We use $u \\in \\{1,\\dots,U\\}$ to index users and $i \\in \\{1,\\dots,I\\}$ to index items. In this work, we consider learning with implicit feedback. The user-by-item interaction matrix is the click matrix $\\mathbf{X} \\in \\mathbb{N}^{U\\times I}$. The lower case $\\mathbf{x}_u =[X_{u1},\\dots,X_{uI}]^\\top \\in \\mathbb{N}^I$ is a bag-of-words vector with the number of clicks for each item from user u. We binarize the click matrix. It is straightforward to extend it to general count data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI37y0ciFYjG"
      },
      "source": [
        "__Generative process__: For each user $u$, the model starts by sampling a $K$-dimensional latent representation $\\mathbf{z}_u$ from a standard Gaussian prior. The latent representation $\\mathbf{z}_u$ is transformed via a non-linear function $f_\\theta (\\cdot) \\in \\mathbb{R}^I$ to produce a probability distribution over $I$ items $\\pi (\\mathbf{z}_u)$ from which the click history $\\mathbf{x}_u$ is assumed to have been drawn:\n",
        "\n",
        "$$\n",
        "\\mathbf{z}_u \\sim \\mathcal{N}(0, \\mathbf{I}_K),  \\pi(\\mathbf{z}_u) \\propto \\exp\\{f_\\theta (\\mathbf{z}_u\\},\\\\\n",
        "\\mathbf{x}_u \\sim \\mathrm{Mult}(N_u, \\pi(\\mathbf{z}_u))\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYCD6bKYFYjH"
      },
      "source": [
        "The objective for Multi-DAE for a single user $u$ is:\n",
        "$$\n",
        "\\mathcal{L}_u(\\theta, \\phi) = \\log p_\\theta(\\mathbf{x}_u | g_\\phi(\\mathbf{x}_u))\n",
        "$$\n",
        "where $g_\\phi(\\cdot)$ is the non-linear \"encoder\" function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNHkjNS_FYjH"
      },
      "source": [
        "class MultiDAE(object):\n",
        "    def __init__(self, p_dims, q_dims=None, lam=0.01, lr=1e-3, random_seed=None):\n",
        "        self.p_dims = p_dims\n",
        "        if q_dims is None:\n",
        "            self.q_dims = p_dims[::-1]\n",
        "        else:\n",
        "            assert q_dims[0] == p_dims[-1], \"Input and output dimension must equal each other for autoencoders.\"\n",
        "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q-network mismatches.\"\n",
        "            self.q_dims = q_dims\n",
        "        self.dims = self.q_dims + self.p_dims[1:]\n",
        "        \n",
        "        self.lam = lam\n",
        "        self.lr = lr\n",
        "        self.random_seed = random_seed\n",
        "\n",
        "        self.construct_placeholders()\n",
        "\n",
        "    def construct_placeholders(self):        \n",
        "        self.input_ph = tf.placeholder(\n",
        "            dtype=tf.float32, shape=[None, self.dims[0]])\n",
        "        self.keep_prob_ph = tf.placeholder_with_default(1.0, shape=None)\n",
        "\n",
        "    def build_graph(self):\n",
        "\n",
        "        self.construct_weights()\n",
        "\n",
        "        saver, logits = self.forward_pass()\n",
        "        log_softmax_var = tf.nn.log_softmax(logits)\n",
        "\n",
        "        # per-user average negative log-likelihood\n",
        "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
        "            log_softmax_var * self.input_ph, axis=1))\n",
        "        # apply regularization to weights\n",
        "        reg = l2_regularizer(self.lam)\n",
        "        reg_var = apply_regularization(reg, self.weights)\n",
        "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
        "        # multiply 2 so that it is back in the same scale\n",
        "        loss = neg_ll + 2 * reg_var\n",
        "        \n",
        "        train_op = tf.train.AdamOptimizer(self.lr).minimize(loss)\n",
        "\n",
        "        # add summary statistics\n",
        "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
        "        tf.summary.scalar('loss', loss)\n",
        "        merged = tf.summary.merge_all()\n",
        "        return saver, logits, loss, train_op, merged\n",
        "\n",
        "    def forward_pass(self):\n",
        "        # construct forward graph        \n",
        "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
        "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
        "        \n",
        "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
        "            h = tf.matmul(h, w) + b\n",
        "            \n",
        "            if i != len(self.weights) - 1:\n",
        "                h = tf.nn.tanh(h)\n",
        "        return tf.train.Saver(), h\n",
        "\n",
        "    def construct_weights(self):\n",
        "\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "        \n",
        "        # define weights\n",
        "        for i, (d_in, d_out) in enumerate(zip(self.dims[:-1], self.dims[1:])):\n",
        "            weight_key = \"weight_{}to{}\".format(i, i+1)\n",
        "            bias_key = \"bias_{}\".format(i+1)\n",
        "            \n",
        "            self.weights.append(tf.get_variable(\n",
        "                name=weight_key, shape=[d_in, d_out],\n",
        "                initializer=tf.contrib.layers.xavier_initializer(\n",
        "                    seed=self.random_seed)))\n",
        "            \n",
        "            self.biases.append(tf.get_variable(\n",
        "                name=bias_key, shape=[d_out],\n",
        "                initializer=tf.truncated_normal_initializer(\n",
        "                    stddev=0.001, seed=self.random_seed)))\n",
        "            \n",
        "            # add summary stats\n",
        "            tf.summary.histogram(weight_key, self.weights[-1])\n",
        "            tf.summary.histogram(bias_key, self.biases[-1])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYKe5hIIFYjK"
      },
      "source": [
        "The objective of Multi-VAE^{PR} (evidence lower-bound, or ELBO) for a single user $u$ is:\n",
        "$$\n",
        "\\mathcal{L}_u(\\theta, \\phi) = \\mathbb{E}_{q_\\phi(z_u | x_u)}[\\log p_\\theta(x_u | z_u)] - \\beta \\cdot KL(q_\\phi(z_u | x_u) \\| p(z_u))\n",
        "$$\n",
        "where $q_\\phi$ is the approximating variational distribution (inference model). $\\beta$ is the additional annealing parameter that we control. The objective of the entire dataset is the average over all the users. It can be trained almost the same as Multi-DAE, thanks to reparametrization trick. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxGbnGCNFYjK"
      },
      "source": [
        "class MultiVAE(MultiDAE):\n",
        "\n",
        "    def construct_placeholders(self):\n",
        "        super(MultiVAE, self).construct_placeholders()\n",
        "\n",
        "        # placeholders with default values when scoring\n",
        "        self.is_training_ph = tf.placeholder_with_default(0., shape=None)\n",
        "        self.anneal_ph = tf.placeholder_with_default(1., shape=None)\n",
        "        \n",
        "    def build_graph(self):\n",
        "        self._construct_weights()\n",
        "\n",
        "        saver, logits, KL = self.forward_pass()\n",
        "        log_softmax_var = tf.nn.log_softmax(logits)\n",
        "\n",
        "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
        "            log_softmax_var * self.input_ph,\n",
        "            axis=-1))\n",
        "        # apply regularization to weights\n",
        "        reg = l2_regularizer(self.lam)\n",
        "        \n",
        "        reg_var = apply_regularization(reg, self.weights_q + self.weights_p)\n",
        "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
        "        # multiply 2 so that it is back in the same scale\n",
        "        neg_ELBO = neg_ll + self.anneal_ph * KL + 2 * reg_var\n",
        "        \n",
        "        train_op = tf.train.AdamOptimizer(self.lr).minimize(neg_ELBO)\n",
        "\n",
        "        # add summary statistics\n",
        "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
        "        tf.summary.scalar('KL', KL)\n",
        "        tf.summary.scalar('neg_ELBO_train', neg_ELBO)\n",
        "        merged = tf.summary.merge_all()\n",
        "\n",
        "        return saver, logits, neg_ELBO, train_op, merged\n",
        "    \n",
        "    def q_graph(self):\n",
        "        mu_q, std_q, KL = None, None, None\n",
        "        \n",
        "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
        "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
        "        \n",
        "        for i, (w, b) in enumerate(zip(self.weights_q, self.biases_q)):\n",
        "            h = tf.matmul(h, w) + b\n",
        "            \n",
        "            if i != len(self.weights_q) - 1:\n",
        "                h = tf.nn.tanh(h)\n",
        "            else:\n",
        "                mu_q = h[:, :self.q_dims[-1]]\n",
        "                logvar_q = h[:, self.q_dims[-1]:]\n",
        "\n",
        "                std_q = tf.exp(0.5 * logvar_q)\n",
        "                KL = tf.reduce_mean(tf.reduce_sum(\n",
        "                        0.5 * (-logvar_q + tf.exp(logvar_q) + mu_q**2 - 1), axis=1))\n",
        "        return mu_q, std_q, KL\n",
        "\n",
        "    def p_graph(self, z):\n",
        "        h = z\n",
        "        \n",
        "        for i, (w, b) in enumerate(zip(self.weights_p, self.biases_p)):\n",
        "            h = tf.matmul(h, w) + b\n",
        "            \n",
        "            if i != len(self.weights_p) - 1:\n",
        "                h = tf.nn.tanh(h)\n",
        "        return h\n",
        "\n",
        "    def forward_pass(self):\n",
        "        # q-network\n",
        "        mu_q, std_q, KL = self.q_graph()\n",
        "        epsilon = tf.random_normal(tf.shape(std_q))\n",
        "\n",
        "        sampled_z = mu_q + self.is_training_ph *\\\n",
        "            epsilon * std_q\n",
        "\n",
        "        # p-network\n",
        "        logits = self.p_graph(sampled_z)\n",
        "        \n",
        "        return tf.train.Saver(), logits, KL\n",
        "\n",
        "    def _construct_weights(self):\n",
        "        self.weights_q, self.biases_q = [], []\n",
        "        \n",
        "        for i, (d_in, d_out) in enumerate(zip(self.q_dims[:-1], self.q_dims[1:])):\n",
        "            if i == len(self.q_dims[:-1]) - 1:\n",
        "                # we need two sets of parameters for mean and variance,\n",
        "                # respectively\n",
        "                d_out *= 2\n",
        "            weight_key = \"weight_q_{}to{}\".format(i, i+1)\n",
        "            bias_key = \"bias_q_{}\".format(i+1)\n",
        "            \n",
        "            self.weights_q.append(tf.get_variable(\n",
        "                name=weight_key, shape=[d_in, d_out],\n",
        "                initializer=tf.contrib.layers.xavier_initializer(\n",
        "                    seed=self.random_seed)))\n",
        "            \n",
        "            self.biases_q.append(tf.get_variable(\n",
        "                name=bias_key, shape=[d_out],\n",
        "                initializer=tf.truncated_normal_initializer(\n",
        "                    stddev=0.001, seed=self.random_seed)))\n",
        "            \n",
        "            # add summary stats\n",
        "            tf.summary.histogram(weight_key, self.weights_q[-1])\n",
        "            tf.summary.histogram(bias_key, self.biases_q[-1])\n",
        "            \n",
        "        self.weights_p, self.biases_p = [], []\n",
        "\n",
        "        for i, (d_in, d_out) in enumerate(zip(self.p_dims[:-1], self.p_dims[1:])):\n",
        "            weight_key = \"weight_p_{}to{}\".format(i, i+1)\n",
        "            bias_key = \"bias_p_{}\".format(i+1)\n",
        "            self.weights_p.append(tf.get_variable(\n",
        "                name=weight_key, shape=[d_in, d_out],\n",
        "                initializer=tf.contrib.layers.xavier_initializer(\n",
        "                    seed=self.random_seed)))\n",
        "            \n",
        "            self.biases_p.append(tf.get_variable(\n",
        "                name=bias_key, shape=[d_out],\n",
        "                initializer=tf.truncated_normal_initializer(\n",
        "                    stddev=0.001, seed=self.random_seed)))\n",
        "            \n",
        "            # add summary stats\n",
        "            tf.summary.histogram(weight_key, self.weights_p[-1])\n",
        "            tf.summary.histogram(bias_key, self.biases_p[-1])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODsCIU-fFYjM"
      },
      "source": [
        "### Training/validation data, hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGSGE8zeFYjM"
      },
      "source": [
        "Load the pre-processed training and validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEfmgezwFYjM"
      },
      "source": [
        "unique_sid = list()\n",
        "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'r') as f:\n",
        "    for line in f:\n",
        "        unique_sid.append(line.strip())\n",
        "\n",
        "n_items = len(unique_sid)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhV3WVq4FYjO"
      },
      "source": [
        "def load_train_data(csv_file):\n",
        "    tp = pd.read_csv(csv_file)\n",
        "    n_users = tp['uid'].max() + 1\n",
        "\n",
        "    rows, cols = tp['uid'], tp['sid']\n",
        "    data = sparse.csr_matrix((np.ones_like(rows),\n",
        "                             (rows, cols)), dtype='float64',\n",
        "                             shape=(n_users, n_items))\n",
        "    return data"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmA2gNL3FYjQ"
      },
      "source": [
        "train_data = load_train_data(os.path.join(pro_dir, 'train.csv'))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1AhXPsNFYjR"
      },
      "source": [
        "def load_tr_te_data(csv_file_tr, csv_file_te):\n",
        "    tp_tr = pd.read_csv(csv_file_tr)\n",
        "    tp_te = pd.read_csv(csv_file_te)\n",
        "\n",
        "    start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n",
        "    end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n",
        "\n",
        "    rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n",
        "    rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n",
        "\n",
        "    data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n",
        "                             (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
        "    data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
        "                             (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
        "    return data_tr, data_te"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "di1oeGm2FYjT"
      },
      "source": [
        "vad_data_tr, vad_data_te = load_tr_te_data(os.path.join(pro_dir, 'validation_tr.csv'),\n",
        "                                           os.path.join(pro_dir, 'validation_te.csv'))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rk8iKyDzFYjV"
      },
      "source": [
        "Set up training hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETG2JNpGFYjW"
      },
      "source": [
        "N = train_data.shape[0]\n",
        "idxlist = range(N)\n",
        "\n",
        "# training batch size\n",
        "batch_size = 1000\n",
        "batches_per_epoch = int(np.ceil(float(N) / batch_size))\n",
        "\n",
        "N_vad = vad_data_tr.shape[0]\n",
        "idxlist_vad = range(N_vad)\n",
        "\n",
        "# validation batch size (since the entire validation set might not fit into GPU memory)\n",
        "batch_size_vad = 2000\n",
        "\n",
        "# the total number of gradient updates for annealing\n",
        "total_anneal_steps = 200000\n",
        "# largest annealing parameter\n",
        "anneal_cap = 0.2"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9hAllGaFYjZ"
      },
      "source": [
        "Evaluate function: Normalized discounted cumulative gain (NDCG@k) and Recall@k"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsRjxtjSFYjZ"
      },
      "source": [
        "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=100):\n",
        "    '''\n",
        "    normalized discounted cumulative gain@k for binary relevance\n",
        "    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n",
        "    '''\n",
        "    batch_users = X_pred.shape[0]\n",
        "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
        "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
        "                       idx_topk_part[:, :k]]\n",
        "    idx_part = np.argsort(-topk_part, axis=1)\n",
        "    # X_pred[np.arange(batch_users)[:, np.newaxis], idx_topk] is the sorted\n",
        "    # topk predicted score\n",
        "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
        "    # build the discount template\n",
        "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
        "\n",
        "    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
        "                         idx_topk].toarray() * tp).sum(axis=1)\n",
        "    IDCG = np.array([(tp[:min(n, k)]).sum()\n",
        "                     for n in heldout_batch.getnnz(axis=1)])\n",
        "    return DCG / IDCG"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQz5SmxzFYjb"
      },
      "source": [
        "def Recall_at_k_batch(X_pred, heldout_batch, k=100):\n",
        "    batch_users = X_pred.shape[0]\n",
        "\n",
        "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
        "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
        "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
        "\n",
        "    X_true_binary = (heldout_batch > 0).toarray()\n",
        "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
        "        np.float32)\n",
        "    recall = tmp / np.minimum(k, X_true_binary.sum(axis=1))\n",
        "    return recall"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3eDxiwkFYjd"
      },
      "source": [
        "### Train a Multi-VAE^{PR}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XTyfWXXFYje"
      },
      "source": [
        "For ML-20M dataset, we set both the generative function $f_\\theta(\\cdot)$ and the inference model $g_\\phi(\\cdot)$ to be 3-layer multilayer perceptron (MLP) with symmetrical architecture. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxge_UC5FYje"
      },
      "source": [
        "The generative function is a [200 -> 600 -> n_items] MLP, which means the inference function is a [n_items -> 600 -> 200] MLP. Thus the overall architecture for the Multi-VAE^{PR} is [n_items -> 600 -> 200 -> 600 -> n_items]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVZTnXauFYje"
      },
      "source": [
        "p_dims = [200, 600, n_items]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUwFoLhRFYjh",
        "outputId": "15be0a50-ea13-4870-94bf-cde6f7d9427e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "tf.reset_default_graph()\n",
        "vae = MultiVAE(p_dims, lam=0.0, random_seed=98765)\n",
        "\n",
        "saver, logits_var, loss_var, train_op_var, merged_var = vae.build_graph()\n",
        "\n",
        "ndcg_var = tf.Variable(0.0)\n",
        "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
        "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
        "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
        "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W1019 05:30:11.206495 140612772943744 deprecation.py:506] From <ipython-input-31-318b0755b4c1>:41: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W1019 05:30:11.426999 140612772943744 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py:1205: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yd73_vSFYjj"
      },
      "source": [
        "Set up logging and checkpoint directory\n",
        "\n",
        "- Change all the logging directory and checkpoint directory to somewhere of your choice\n",
        "- Monitor training progress using tensorflow by: `tensorboard --logdir=$log_dir`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDzGG4VnFYjj"
      },
      "source": [
        "arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in vae.dims[1:-1]]))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HRfL9eXFYjl",
        "outputId": "60428f1a-35ce-471b-fbaa-335a892170a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "log_dir = '/content/log/ml-20m/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
        "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
        "\n",
        "if os.path.exists(log_dir):\n",
        "    shutil.rmtree(log_dir)\n",
        "\n",
        "print(\"log directory: %s\" % log_dir)\n",
        "summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "log directory: /content/log/ml-20m/VAE_anneal200K_cap2.0E-01/I-600-200-600-I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Onllv_KFFYjn",
        "outputId": "5896f32f-a65d-4c9a-ee68-fcd32d4e5844",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "chkpt_dir = '/content/chkpt/ml-20m/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
        "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
        "\n",
        "if not os.path.isdir(chkpt_dir):\n",
        "    os.makedirs(chkpt_dir) \n",
        "    \n",
        "print(\"chkpt directory: %s\" % chkpt_dir)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chkpt directory: /content/chkpt/ml-20m/VAE_anneal200K_cap2.0E-01/I-600-200-600-I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEUws3MBFYjo"
      },
      "source": [
        "n_epochs = 20"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xjH1qvYQ1t_"
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ceanmc5-FYjr",
        "outputId": "370d17fa-1ee2-489d-f3b2-4939f18a49ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ndcgs_vad = []\n",
        "\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    init = tf.global_variables_initializer()\n",
        "    sess.run(init)\n",
        "\n",
        "    best_ndcg = -np.inf\n",
        "\n",
        "    update_count = 0.0\n",
        "    \n",
        "    for epoch in tqdm(range(n_epochs)):\n",
        "        np.random.shuffle(idxlist)\n",
        "        # train for one epoch\n",
        "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
        "            end_idx = min(st_idx + batch_size, N)\n",
        "            X = train_data[idxlist[st_idx:end_idx]]\n",
        "            \n",
        "            if sparse.isspmatrix(X):\n",
        "                X = X.toarray()\n",
        "            X = X.astype('float32')           \n",
        "            \n",
        "            if total_anneal_steps > 0:\n",
        "                anneal = min(anneal_cap, 1. * update_count / total_anneal_steps)\n",
        "            else:\n",
        "                anneal = anneal_cap\n",
        "            \n",
        "            feed_dict = {vae.input_ph: X, \n",
        "                         vae.keep_prob_ph: 0.5, \n",
        "                         vae.anneal_ph: anneal,\n",
        "                         vae.is_training_ph: 1}        \n",
        "            sess.run(train_op_var, feed_dict=feed_dict)\n",
        "\n",
        "            if bnum % 100 == 0:\n",
        "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
        "                summary_writer.add_summary(summary_train, \n",
        "                                           global_step=epoch * batches_per_epoch + bnum) \n",
        "            \n",
        "            update_count += 1\n",
        "        \n",
        "        # compute validation NDCG\n",
        "        ndcg_dist = []\n",
        "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
        "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
        "            X = vad_data_tr[idxlist_vad[st_idx:end_idx]]\n",
        "\n",
        "            if sparse.isspmatrix(X):\n",
        "                X = X.toarray()\n",
        "            X = X.astype('float32')\n",
        "        \n",
        "            pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X} )\n",
        "            # exclude examples from training and validation (if any)\n",
        "            pred_val[X.nonzero()] = -np.inf\n",
        "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, vad_data_te[idxlist_vad[st_idx:end_idx]]))\n",
        "        \n",
        "        ndcg_dist = np.concatenate(ndcg_dist)\n",
        "        ndcg_ = ndcg_dist.mean()\n",
        "        ndcgs_vad.append(ndcg_)\n",
        "        merged_valid_val = sess.run(merged_valid, feed_dict={ndcg_var: ndcg_, ndcg_dist_var: ndcg_dist})\n",
        "        summary_writer.add_summary(merged_valid_val, epoch)\n",
        "\n",
        "        # update the best model (if necessary)\n",
        "        if ndcg_ > best_ndcg:\n",
        "            saver.save(sess, '{}/model'.format(chkpt_dir))\n",
        "            best_ndcg = ndcg_"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [06:30<00:00, 19.39s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LemP9VhNFYjt",
        "outputId": "e0289eb7-070d-4224-ec64-19e02d85de3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "source": [
        "plt.figure(figsize=(12, 3))\n",
        "plt.plot(ndcgs_vad)\n",
        "plt.ylabel(\"Validation NDCG@100\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "pass"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeMzPudfFYju"
      },
      "source": [
        "### Load the test data and compute test metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsRAPEkFFYju"
      },
      "source": [
        "test_data_tr, test_data_te = load_tr_te_data(\n",
        "    os.path.join(pro_dir, 'test_tr.csv'),\n",
        "    os.path.join(pro_dir, 'test_te.csv'))"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldrY0hJhFYjx"
      },
      "source": [
        "N_test = test_data_tr.shape[0]\n",
        "idxlist_test = range(N_test)\n",
        "\n",
        "batch_size_test = 2000"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKENimMVFYjz"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "vae = MultiVAE(p_dims, lam=0.0)\n",
        "saver, logits_var, _, _, _ = vae.build_graph()    "
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZsTJ6wPFYj0"
      },
      "source": [
        "Load the best performing model on the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkeAm-doFYj1",
        "outputId": "b1d9191b-9a74-4817-e308-f46d6902b60d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "chkpt_dir = '/content/chkpt/ml-20m/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
        "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
        "print(\"chkpt directory: %s\" % chkpt_dir)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chkpt directory: /content/chkpt/ml-20m/VAE_anneal200K_cap2.0E-01/I-600-200-600-I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBd_FOB3FYj5",
        "outputId": "ab63e0f5-8abc-4c97-efa4-e4eecf276890",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "n100_list, r20_list, r50_list = [], [], []\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
        "\n",
        "    for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
        "        end_idx = min(st_idx + batch_size_test, N_test)\n",
        "        X = test_data_tr[idxlist_test[st_idx:end_idx]]\n",
        "\n",
        "        if sparse.isspmatrix(X):\n",
        "            X = X.toarray()\n",
        "        X = X.astype('float32')\n",
        "\n",
        "        pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X})\n",
        "        # exclude examples from training and validation (if any)\n",
        "        pred_val[X.nonzero()] = -np.inf\n",
        "        n100_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=100))\n",
        "        r20_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=20))\n",
        "        r50_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=50))\n",
        "    \n",
        "n100_list = np.concatenate(n100_list)\n",
        "r20_list = np.concatenate(r20_list)\n",
        "r50_list = np.concatenate(r50_list)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W1019 05:37:49.144450 140612772943744 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5jiCJtjFYj6",
        "outputId": "c786a669-9d55-4b23-b5eb-cc5b11a77b53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(\"Test NDCG@100=%.5f (%.5f)\" % (np.mean(n100_list), np.std(n100_list) / np.sqrt(len(n100_list))))\n",
        "print(\"Test Recall@20=%.5f (%.5f)\" % (np.mean(r20_list), np.std(r20_list) / np.sqrt(len(r20_list))))\n",
        "print(\"Test Recall@50=%.5f (%.5f)\" % (np.mean(r50_list), np.std(r50_list) / np.sqrt(len(r50_list))))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test NDCG@100=0.40965 (0.00208)\n",
            "Test Recall@20=0.38218 (0.00270)\n",
            "Test Recall@50=0.52284 (0.00289)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_UQqKHTbW2Y"
      },
      "source": [
        "## Activity\n",
        "Train and test multi-DAE model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dt6c7n3vFYj8"
      },
      "source": [
        "### Train a Multi-DAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sxbccfxFYj8"
      },
      "source": [
        "The generative function is a [200 -> n_items] MLP, thus the overall architecture for the Multi-DAE is [n_items -> 200 -> n_items]. We find this architecture achieves better validation NDCG@100 than the [n_items -> 600 -> 200 -> 600 -> n_items] architecture as used in Multi-VAE^{PR}."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtERLP50FYj8"
      },
      "source": [
        "p_dims = [200, n_items]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj2JohEIFYj-"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "dae = MultiDAE(p_dims, lam=0.01 / batch_size, random_seed=98765)\n",
        "\n",
        "saver, logits_var, loss_var, train_op_var, merged_var = dae.build_graph()\n",
        "\n",
        "ndcg_var = tf.Variable(0.0)\n",
        "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
        "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
        "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
        "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oTDQAmdFYkA"
      },
      "source": [
        "Set up logging and checkpoint directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-47-HpT4FYkA"
      },
      "source": [
        "arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in dae.dims[1:-1]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ss1ShooFYkD",
        "outputId": "5e742c77-ec2f-4e8c-a918-f2eecc9cf0aa"
      },
      "source": [
        "log_dir = '/content/log/ml-20m/DAE/{}'.format(arch_str)\n",
        "\n",
        "if os.path.exists(log_dir):\n",
        "    shutil.rmtree(log_dir)\n",
        "\n",
        "print(\"log directory: %s\" % log_dir)\n",
        "summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "log directory: /content/log/ml-20m/DAE/I-200-I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHnoMeb2FYkF",
        "outputId": "83c11137-c064-4abe-8c34-28cb200e8010"
      },
      "source": [
        "chkpt_dir = '/content/chkpt/ml-20m/DAE/{}'.format(arch_str)\n",
        "\n",
        "if not os.path.isdir(chkpt_dir):\n",
        "    os.makedirs(chkpt_dir) \n",
        "    \n",
        "print(\"chkpt directory: %s\" % chkpt_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chkpt directory: /content/chkpt/ml-20m/DAE/I-200-I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXTkHeCwFYkH"
      },
      "source": [
        "n_epochs = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUWc5lnHFYkI"
      },
      "source": [
        "ndcgs_vad = []\n",
        "\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    init = tf.global_variables_initializer()\n",
        "    sess.run(init)\n",
        "\n",
        "    best_ndcg = -np.inf\n",
        "    \n",
        "    for epoch in tqdm(range(n_epochs)):\n",
        "        np.random.shuffle(idxlist)\n",
        "        # train for one epoch\n",
        "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
        "            end_idx = min(st_idx + batch_size, N)\n",
        "            X = train_data[idxlist[st_idx:end_idx]]\n",
        "            \n",
        "            if sparse.isspmatrix(X):\n",
        "                X = X.toarray()\n",
        "            X = X.astype('float32')           \n",
        "            \n",
        "            feed_dict = {dae.input_ph: X, \n",
        "                         dae.keep_prob_ph: 0.5}        \n",
        "            sess.run(train_op_var, feed_dict=feed_dict)\n",
        "\n",
        "            if bnum % 100 == 0:\n",
        "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
        "                summary_writer.add_summary(summary_train, global_step=epoch * batches_per_epoch + bnum) \n",
        "                    \n",
        "        # compute validation NDCG\n",
        "        ndcg_dist = []\n",
        "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
        "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
        "            X = vad_data_tr[idxlist_vad[st_idx:end_idx]]\n",
        "\n",
        "            if sparse.isspmatrix(X):\n",
        "                X = X.toarray()\n",
        "            X = X.astype('float32')\n",
        "        \n",
        "            pred_val = sess.run(logits_var, feed_dict={dae.input_ph: X} )\n",
        "            # exclude examples from training and validation (if any)\n",
        "            pred_val[X.nonzero()] = -np.inf\n",
        "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, vad_data_te[idxlist_vad[st_idx:end_idx]]))\n",
        "        \n",
        "        ndcg_dist = np.concatenate(ndcg_dist)\n",
        "        ndcg_ = ndcg_dist.mean()\n",
        "        ndcgs_vad.append(ndcg_)\n",
        "        merged_valid_val = sess.run(merged_valid, feed_dict={ndcg_var: ndcg_, ndcg_dist_var: ndcg_dist})\n",
        "        summary_writer.add_summary(merged_valid_val, epoch)\n",
        "\n",
        "        # update the best model (if necessary)\n",
        "        if ndcg_ > best_ndcg:\n",
        "            saver.save(sess, '{}/model'.format(chkpt_dir))\n",
        "            best_ndcg = ndcg_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8sTDoZEFYkK",
        "outputId": "7cf1c429-645d-4a7d-bb0d-cf5d30dfdb74"
      },
      "source": [
        "plt.figure(figsize=(12, 3))\n",
        "plt.plot(ndcgs_vad)\n",
        "plt.ylabel(\"Validation NDCG@100\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtoAAADQCAYAAAA56sZ8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOB7bfwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fe6de861690>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBtAk0mYFYkM"
      },
      "source": [
        "### Compute test metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ8KXJslFYkN"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "dae = MultiDAE(p_dims, lam=0.01 / batch_size)\n",
        "saver, logits_var, _, _, _ = dae.build_graph()    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_wplMBeFYkO"
      },
      "source": [
        "Load the best performing model on the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvLyop0oFYkO",
        "outputId": "1bdc096e-0a40-4082-c2ae-cf7998ddc2cd"
      },
      "source": [
        "chkpt_dir = '/volmount/chkpt/ml-20m/DAE/{}'.format(arch_str)\n",
        "print(\"chkpt directory: %s\" % chkpt_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chkpt directory: /volmount/chkpt/ml-20m/DAE/I-200-I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jONQoamqFYkQ"
      },
      "source": [
        "n100_list, r20_list, r50_list = [], [], []\n",
        "\n",
        "with tf.Session() as sess:    \n",
        "    saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
        "    \n",
        "    for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
        "        end_idx = min(st_idx + batch_size_test, N_test)\n",
        "        X = test_data_tr[idxlist_test[st_idx:end_idx]]\n",
        "\n",
        "        if sparse.isspmatrix(X):\n",
        "            X = X.toarray()\n",
        "        X = X.astype('float32')\n",
        "\n",
        "        pred_val = sess.run(logits_var, feed_dict={dae.input_ph: X})\n",
        "        # exclude examples from training and validation (if any)\n",
        "        pred_val[X.nonzero()] = -np.inf\n",
        "        n100_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=100))\n",
        "        r20_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=20))\n",
        "        r50_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=50))\n",
        "\n",
        "n100_list = np.concatenate(n100_list)\n",
        "r20_list = np.concatenate(r20_list)\n",
        "r50_list = np.concatenate(r50_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jUmIokmFYkR",
        "outputId": "e693487b-7413-45b6-9c5f-bb25d73c35dd"
      },
      "source": [
        "print(\"Test NDCG@100=%.5f (%.5f)\" % (np.mean(n100_list), np.std(n100_list) / np.sqrt(len(n100_list))))\n",
        "print(\"Test Recall@20=%.5f (%.5f)\" % (np.mean(r20_list), np.std(r20_list) / np.sqrt(len(r20_list))))\n",
        "print(\"Test Recall@50=%.5f (%.5f)\" % (np.mean(r50_list), np.std(r50_list) / np.sqrt(len(r50_list))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test NDCG@100=0.41997 (0.00212)\n",
            "Test Recall@20=0.38768 (0.00268)\n",
            "Test Recall@50=0.52426 (0.00284)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
